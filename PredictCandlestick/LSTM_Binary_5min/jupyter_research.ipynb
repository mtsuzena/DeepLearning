{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Min Binary Options Predictions on FX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM method (Long-term short-term memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries to train LSTM deep nerual network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mpl_finance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c48cb71ce852>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdates\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmdates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mticker\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmticker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmpl_finance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcandlestick_ohlc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mpl_finance'"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import sklearn\n",
    "import keras\n",
    "#import tensorflow\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mticker\n",
    "from mpl_finance import candlestick_ohlc\n",
    "import numpy as np\n",
    "import urllib\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "\n",
    "print('Numpy version: ' + np.__version__)\n",
    "print('Pandas version: ' + pd.__version__)\n",
    "print('Matplotlib version: ' + matplotlib.__version__)\n",
    "print('Sklearn version: ' + sklearn.__version__)\n",
    "print('Keras version: ' + keras.__version__)\n",
    "#print('Tensorflow-gpu version: ' + tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSI function - Relative strength index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_strength(prices, n=14):\n",
    "\n",
    "    deltas = np.diff(prices)\n",
    "    seed = deltas[:n+1]\n",
    "    up = seed[seed >= 0].sum()/n\n",
    "    down = -seed[seed < 0].sum()/n\n",
    "    rs = up/down\n",
    "    rsi = np.zeros_like(prices)\n",
    "    rsi[:n] = 100. - 100./(1. + rs)\n",
    "\n",
    "    for i in range(n, len(prices)):\n",
    "        delta = deltas[i - 1]  # cause the diff is 1 shorter\n",
    "\n",
    "        if delta > 0:\n",
    "            upval = delta\n",
    "            downval = 0.\n",
    "        else:\n",
    "            upval = 0.\n",
    "            downval = -delta\n",
    "\n",
    "        up = (up*(n - 1) + upval)/n\n",
    "        down = (down*(n - 1) + downval)/n\n",
    "\n",
    "        rs = up/down\n",
    "        rsi[i] = 100. - 100./(1. + rs)\n",
    "\n",
    "    return rsi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main feature enginering function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureEnginering(MyRawData):\n",
    "\n",
    "\n",
    "    MyRawData['Gmt time'] = pd.to_datetime(MyRawData['Gmt time'], format='%d.%m.%Y %H:%M:%S.000', utc=True)\n",
    "    \n",
    "    no_of_std = 2\n",
    "\n",
    "    MyRawData['MA_30MA'] = MyRawData['Close'].rolling(window=30).mean()\n",
    "    MyRawData['MA_30MA_std'] = MyRawData['Close'].rolling(window=30).std() \n",
    "    MyRawData['MA_30MA_BB_high'] = MyRawData['MA_30MA'] + no_of_std * MyRawData['MA_30MA_std']\n",
    "    MyRawData['MA_30MA_BB_low'] = MyRawData['MA_30MA'] - no_of_std * MyRawData['MA_30MA_std']\n",
    "\n",
    "    MyRawData['RSI'] =relative_strength(MyRawData['Close'])\n",
    "\n",
    "    del MyRawData['Volume']\n",
    "    del MyRawData['Gmt time']\n",
    "    del MyRawData['MA_30MA_std']\n",
    "\n",
    "    return MyRawData\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to plot candlesticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_data_ohlc(dataset):\n",
    "    fig = plt.figure()\n",
    "    ax1 = plt.subplot2grid((1,1), (0,0))\n",
    "    closep=dataset[:,[3]]\n",
    "    highp=dataset[:,[1]]\n",
    "    lowp=dataset[:,[2]]\n",
    "    openp=dataset[:,[0]]\n",
    "    date=range(len(closep))\n",
    "    MA_30MA = dataset[:,[4]]\n",
    "    MA_30MA_std = dataset[:,[5]]\n",
    "    MA_30MA_BB_low = dataset[:,[6]]\n",
    "    MA_30MA_BB_high = dataset[:,[7]]\n",
    "    RSI = dataset[:,[8]]\n",
    "    \n",
    "    \n",
    "    x = 0\n",
    "    y = len(date)\n",
    "    ohlc = []\n",
    "    while x < y:\n",
    "        append_me = date[x], openp[x], highp[x], lowp[x], closep[x]\n",
    "        ohlc.append(append_me)\n",
    "        x+=1\n",
    "    candlestick_ohlc(ax1, ohlc, width=0.4, colorup='#77d879', colordown='#db3f3f')\n",
    "    for label in ax1.xaxis.get_ticklabels():\n",
    "        label.set_rotation(45)\n",
    "    ax1.xaxis.set_major_locator(mticker.MaxNLocator(10))\n",
    "    ax1.grid(True)\n",
    "    plt.xlabel('Candle')\n",
    "    plt.ylabel('Price')\n",
    "    plt.title('Candlestick sample representation')\n",
    "    plt.legend()\n",
    "    \n",
    "    ax1.plot(date, MA_30MA)\n",
    "    ax1.plot(date, MA_30MA_BB_low)\n",
    "    ax1.plot(date, MA_30MA_BB_high)\n",
    "    \n",
    "    plt.subplots_adjust(left=0.09, bottom=0.20, right=0.94, top=0.90, wspace=0.2, hspace=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('EURUSD_2010_2018.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gmt time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.01.2010 00:00:00.000</td>\n",
       "      <td>1.43283</td>\n",
       "      <td>1.43283</td>\n",
       "      <td>1.43267</td>\n",
       "      <td>1.43267</td>\n",
       "      <td>74.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.01.2010 00:01:00.000</td>\n",
       "      <td>1.43268</td>\n",
       "      <td>1.43285</td>\n",
       "      <td>1.43268</td>\n",
       "      <td>1.43284</td>\n",
       "      <td>25.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.01.2010 00:02:00.000</td>\n",
       "      <td>1.43280</td>\n",
       "      <td>1.43280</td>\n",
       "      <td>1.43268</td>\n",
       "      <td>1.43280</td>\n",
       "      <td>30.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.01.2010 00:03:00.000</td>\n",
       "      <td>1.43280</td>\n",
       "      <td>1.43280</td>\n",
       "      <td>1.43268</td>\n",
       "      <td>1.43273</td>\n",
       "      <td>41.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.01.2010 00:04:00.000</td>\n",
       "      <td>1.43283</td>\n",
       "      <td>1.43283</td>\n",
       "      <td>1.43277</td>\n",
       "      <td>1.43277</td>\n",
       "      <td>53.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Gmt time     Open     High      Low    Close  Volume\n",
       "0  01.01.2010 00:00:00.000  1.43283  1.43283  1.43267  1.43267    74.3\n",
       "1  01.01.2010 00:01:00.000  1.43268  1.43285  1.43268  1.43284    25.4\n",
       "2  01.01.2010 00:02:00.000  1.43280  1.43280  1.43268  1.43280    30.9\n",
       "3  01.01.2010 00:03:00.000  1.43280  1.43280  1.43268  1.43273    41.9\n",
       "4  01.01.2010 00:04:00.000  1.43283  1.43283  1.43277  1.43277    53.8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature enginered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FeatureEnginering' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-355d1ad90bf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureEnginering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'FeatureEnginering' is not defined"
     ]
    }
   ],
   "source": [
    "data_set = FeatureEnginering(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gmt time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3363308</th>\n",
       "      <td>31.12.2018 21:56:00.000</td>\n",
       "      <td>1.14637</td>\n",
       "      <td>1.14642</td>\n",
       "      <td>1.14624</td>\n",
       "      <td>1.14642</td>\n",
       "      <td>94.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3363309</th>\n",
       "      <td>31.12.2018 21:57:00.000</td>\n",
       "      <td>1.14642</td>\n",
       "      <td>1.14647</td>\n",
       "      <td>1.14640</td>\n",
       "      <td>1.14645</td>\n",
       "      <td>89.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3363310</th>\n",
       "      <td>31.12.2018 21:58:00.000</td>\n",
       "      <td>1.14645</td>\n",
       "      <td>1.14674</td>\n",
       "      <td>1.14639</td>\n",
       "      <td>1.14672</td>\n",
       "      <td>96.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3363311</th>\n",
       "      <td>31.12.2018 21:59:00.000</td>\n",
       "      <td>1.14671</td>\n",
       "      <td>1.14671</td>\n",
       "      <td>1.14635</td>\n",
       "      <td>1.14644</td>\n",
       "      <td>26.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3363312</th>\n",
       "      <td>31.12.2018 22:00:00.000</td>\n",
       "      <td>1.14644</td>\n",
       "      <td>1.14644</td>\n",
       "      <td>1.14627</td>\n",
       "      <td>1.14627</td>\n",
       "      <td>5.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Gmt time     Open     High      Low    Close  Volume\n",
       "3363308  31.12.2018 21:56:00.000  1.14637  1.14642  1.14624  1.14642   94.97\n",
       "3363309  31.12.2018 21:57:00.000  1.14642  1.14647  1.14640  1.14645   89.03\n",
       "3363310  31.12.2018 21:58:00.000  1.14645  1.14674  1.14639  1.14672   96.00\n",
       "3363311  31.12.2018 21:59:00.000  1.14671  1.14671  1.14635  1.14644   26.77\n",
       "3363312  31.12.2018 22:00:00.000  1.14644  1.14644  1.14627  1.14627    5.25"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-557e62248e20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_set' is not defined"
     ]
    }
   ],
   "source": [
    "data_set = data_set.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_max_scaler = preprocessing.MinMaxScaler()\n",
    "#data_set = min_max_scaler.fit_transform(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6f46807c0031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_set' is not defined"
     ]
    }
   ],
   "source": [
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_price_to_pips(conversion_array):\n",
    "    #Open\tHigh\tLow \tClose\tMA_30MA \tMA_30MA_BB_high \tMA_30MA_BB_low\tRSI\n",
    "    #Open-->Wicks up\n",
    "    #High-->Wicks down\n",
    "    #Low-->Body size\n",
    "    #dClose-->Candle type {1,-1}\n",
    "    #MA_30MA-->(Close - MA_30MA)\n",
    "    #MA_30MA_BB_high-->(Close -  MA_30MA_BB_high)\n",
    "    #MA_30MA_BB_low-->(Close - MA_30MA_BB_low)\n",
    "    #RSI--> (RSI * 0.01)\n",
    "    \n",
    "\n",
    "    if conversion_array[3]>conversion_array[0]:\n",
    "        candle_type=1\n",
    "        wicks_up=conversion_array[1]-conversion_array[3]\n",
    "        wicks_down=conversion_array[2]-conversion_array[0]\n",
    "        body_size=conversion_array[3]-conversion_array[0]\n",
    "    else:\n",
    "        candle_type=-1\n",
    "        wicks_up=conversion_array[1]-conversion_array[0]\n",
    "        wicks_down=conversion_array[2]-conversion_array[3]\n",
    "        body_size=conversion_array[1]-conversion_array[3]\n",
    "    \n",
    "    MA=conversion_array[4]-conversion_array[3]\n",
    "    BB_high=conversion_array[5]-conversion_array[3]\n",
    "    BB_high=conversion_array[6]-conversion_array[3]\n",
    "    RSI=conversion_array[7]*0.01\n",
    "    \n",
    "    conversion_array[0]=candle_type\n",
    "    conversion_array[1]=wicks_up\n",
    "    conversion_array[2]=wicks_down\n",
    "    conversion_array[3]=body_size\n",
    "    conversion_array[4]=MA\n",
    "    conversion_array[5]=BB_high\n",
    "    conversion_array[6]=BB_high\n",
    "    conversion_array[7]=RSI\n",
    "    \n",
    "    return conversion_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_pips(data, lookback, delay, min_index, max_index,\n",
    "              shuffle=False, batch_size=128, step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(\n",
    "                min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "\n",
    "        samples = np.zeros((len(rows),\n",
    "                           lookback // step,\n",
    "                           data.shape[-1]))\n",
    "        targets = np.zeros((len(rows),))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = data[indices]\n",
    "            \n",
    "            if data[rows[j] + delay][3] > data[rows[j]][3]:\n",
    "                targets[j] = 1\n",
    "            else:\n",
    "                targets[j] = 0\n",
    "        yield samples, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generator(data, lookback, delay, min_index, max_index,\n",
    "              shuffle=False, batch_size=128, step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(\n",
    "                min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "\n",
    "        samples = np.zeros((len(rows),\n",
    "                           lookback // step,\n",
    "                           data.shape[-1]))\n",
    "        targets = np.zeros((len(rows),))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            \n",
    "            #min_max_scaler = preprocessing.MinMaxScaler()\n",
    "            new_samples=[]\n",
    "            for h in data[indices]:\n",
    "                new_samples.append(convert_price_to_pips(h)) \n",
    "        \n",
    "            new_samples = np.array(new_samples)\n",
    "            #new_samples = min_max_scaler.fit_transform(new_samples)\n",
    "            \n",
    "            samples[j] = data[indices]\n",
    "            #samples[j] = new_samples\n",
    "            \n",
    "            if data[rows[j] + delay][3] > data[rows[j]][3]:\n",
    "                targets[j] = 1\n",
    "            else:\n",
    "                targets[j] = 0\n",
    "        yield samples, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f0ea5cc4922f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m train_gen = generator(data_set,\n\u001b[0m\u001b[1;32m      7\u001b[0m                       \u001b[0mlookback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlookback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                       \u001b[0mdelay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_set' is not defined"
     ]
    }
   ],
   "source": [
    "lookback = 50\n",
    "step = 1\n",
    "delay = 60\n",
    "batch_size = 500\n",
    "\n",
    "train_gen = generator(data_set,\n",
    "                      lookback=lookback,\n",
    "                      delay=delay,\n",
    "                      min_index=0,\n",
    "                      max_index=2000000,\n",
    "                      shuffle=False,\n",
    "                      step=step, \n",
    "                      batch_size=batch_size)\n",
    "val_gen = generator(data_set,\n",
    "                    lookback=lookback,\n",
    "                    delay=delay,\n",
    "                    min_index=2000001,\n",
    "                    max_index=3000000,\n",
    "                    step=step,\n",
    "                    batch_size=batch_size)\n",
    "test_gen = generator(data_set,\n",
    "                     lookback=lookback,\n",
    "                     delay=delay,\n",
    "                     min_index=3000001,\n",
    "                     max_index=None,\n",
    "                     step=step,\n",
    "                     batch_size=batch_size)\n",
    "\n",
    "# Liczba kroków pobierania danych z obiektu val_gen \n",
    "# zapewniających przetworzenie całego walidacyjnego zbioru danych.\n",
    "val_steps = (3000000 - 2000001 - lookback) // batch_size\n",
    "\n",
    "# Liczba kroków pobierania danych z obiektu test_gen, \n",
    "# przy której przetworzony zostanie cały testowy zbiór danych.\n",
    "test_steps = (len(data_set) - 3000001 - lookback) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testooos():\n",
    "    test = next(train_gen)\n",
    "    graph_data_ohlc(test[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_gen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-626072fb99b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_gen' is not defined"
     ]
    }
   ],
   "source": [
    "print(next(train_gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import time\n",
    "starttime=time.time()\n",
    "while True:\n",
    "    testooos()\n",
    "    time.sleep(1.0 - ((time.time() - starttime) % 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d510a614baa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#model = Sequential()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "###### from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#model = Sequential()\n",
    "#model.add(layers.GRU(32,\n",
    "   #                  dropout=0.2,\n",
    "  #                   recurrent_dropout=0.2,\n",
    "  #                   input_shape=(None, float_data.shape[-1])))\n",
    "#model.add(layers.Dense(1))\n",
    "\n",
    "model.add(layers.CuDNNLSTM(units = 50, return_sequences = True, input_shape = (None, data_set.shape[-1])))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.CuDNNLSTM(units = 50, return_sequences = True))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.CuDNNLSTM(units = 50, return_sequences = True))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.CuDNNLSTM(units = 50))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Dense(units = 1))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=500,\n",
    "                              epochs=20,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Strata trenowania')\n",
    "plt.plot(epochs, val_loss, 'b', label='Strata walidacji')\n",
    "plt.title('Strata trenowania i walidacji')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`steps=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `steps` or use the `keras.utils.Sequence` class.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-25cb74022a2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1275\u001b[0m                 \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m                 \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m                 use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1715\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             raise ValueError('`steps=None` is only valid for a generator'\n\u001b[0m\u001b[1;32m    306\u001b[0m                              \u001b[0;34m' based on the `keras.utils.Sequence` class.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                              \u001b[0;34m' Please specify `steps` or use the'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `steps=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `steps` or use the `keras.utils.Sequence` class."
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_gen)\n",
    "print('Test accuracy:', test_acc)\n",
    "predictions = model.predict_generator(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
