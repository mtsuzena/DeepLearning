{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from pandas_datareader import data as web\n",
    "from matplotlib import pyplot as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zscore = lambda x:(x -x.mean())/x.std() # zscore: normalization of log returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = datetime.datetime(2000,1,1)\n",
    "end = datetime.datetime(2016,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = web.DataReader(\"GOOGL\", \"google\", start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data(data, n_prev):  \n",
    "    \"\"\"\n",
    "    data should be pd.DataFrame()\n",
    "    \"\"\"\n",
    "\n",
    "    docX, docY = [], []\n",
    "    for i in range(len(data)-n_prev):\n",
    "        zscore(data.iloc[i:i+n_prev+1])\n",
    "        docX.append(zscore(data.iloc[i:i+n_prev]).as_matrix())\n",
    "        docY.append(zscore(data.iloc[i:i+n_prev+1]).Close[30])\n",
    "    alsX = np.array(docX)\n",
    "    alsY = np.array(docY)\n",
    "    \n",
    "    return alsX, alsY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size=0.1):  \n",
    "    \"\"\"\n",
    "    This just splits data to training and testing parts\n",
    "    \"\"\"\n",
    "    ntrn = int(round(len(df) * (1 - test_size)))\n",
    "\n",
    "    X_train, y_train = _load_data(df.iloc[0:ntrn],30)\n",
    "    X_test, y_test = _load_data(df.iloc[ntrn:],30)\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 300)               367200    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 301       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 367,501\n",
      "Trainable params: 367,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential  \n",
    "from keras.layers.core import Dense, Activation, Dropout \n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "\n",
    "hidden_neurons = 300\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(300, input_shape=(30, 5), return_sequences=False))       \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"tanh\"))\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"Adam\",  metrics=['accuracy'])  \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2418 samples, validate on 128 samples\n",
      "Epoch 1/40\n",
      "2418/2418 [==============================] - 9s - loss: 0.8426 - acc: 0.0000e+00 - val_loss: 0.6902 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.6457 - acc: 0.0000e+00 - val_loss: 0.6245 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.6119 - acc: 0.0000e+00 - val_loss: 0.6046 - val_acc: 0.0000e+00\n",
      "Epoch 4/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5923 - acc: 0.0000e+00 - val_loss: 0.5918 - val_acc: 0.0000e+00\n",
      "Epoch 5/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5872 - acc: 0.0000e+00 - val_loss: 0.5793 - val_acc: 0.0000e+00\n",
      "Epoch 6/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5782 - acc: 0.0000e+00 - val_loss: 0.5888 - val_acc: 0.0000e+00\n",
      "Epoch 7/40\n",
      "2418/2418 [==============================] - 9s - loss: 0.5779 - acc: 0.0000e+00 - val_loss: 0.5715 - val_acc: 0.0000e+00\n",
      "Epoch 8/40\n",
      "2418/2418 [==============================] - 9s - loss: 0.5726 - acc: 0.0000e+00 - val_loss: 0.5718 - val_acc: 0.0000e+00\n",
      "Epoch 9/40\n",
      "2418/2418 [==============================] - 9s - loss: 0.5654 - acc: 0.0000e+00 - val_loss: 0.5770 - val_acc: 0.0000e+00\n",
      "Epoch 10/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5770 - acc: 0.0000e+00 - val_loss: 0.5600 - val_acc: 0.0000e+00\n",
      "Epoch 11/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5723 - acc: 0.0000e+00 - val_loss: 0.5649 - val_acc: 0.0000e+00\n",
      "Epoch 12/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5695 - acc: 0.0000e+00 - val_loss: 0.5689 - val_acc: 0.0000e+00\n",
      "Epoch 13/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5637 - acc: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.0000e+00\n",
      "Epoch 14/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5610 - acc: 0.0000e+00 - val_loss: 0.5574 - val_acc: 0.0000e+00\n",
      "Epoch 15/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5610 - acc: 0.0000e+00 - val_loss: 0.5583 - val_acc: 0.0000e+00\n",
      "Epoch 16/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5607 - acc: 0.0000e+00 - val_loss: 0.5605 - val_acc: 0.0000e+00\n",
      "Epoch 17/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5581 - acc: 0.0000e+00 - val_loss: 0.5817 - val_acc: 0.0000e+00\n",
      "Epoch 18/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5605 - acc: 0.0000e+00 - val_loss: 0.5570 - val_acc: 0.0000e+00\n",
      "Epoch 19/40\n",
      "2418/2418 [==============================] - 9s - loss: 0.5579 - acc: 0.0000e+00 - val_loss: 0.5559 - val_acc: 0.0000e+00\n",
      "Epoch 20/40\n",
      "2418/2418 [==============================] - 9s - loss: 0.5561 - acc: 0.0000e+00 - val_loss: 0.5545 - val_acc: 0.0000e+00\n",
      "Epoch 21/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5563 - acc: 0.0000e+00 - val_loss: 0.5618 - val_acc: 0.0000e+00\n",
      "Epoch 22/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5574 - acc: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.0000e+00\n",
      "Epoch 23/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5538 - acc: 0.0000e+00 - val_loss: 0.5621 - val_acc: 0.0000e+00\n",
      "Epoch 24/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5539 - acc: 0.0000e+00 - val_loss: 0.5437 - val_acc: 0.0000e+00\n",
      "Epoch 25/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5501 - acc: 0.0000e+00 - val_loss: 0.5551 - val_acc: 0.0000e+00\n",
      "Epoch 26/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5555 - acc: 0.0000e+00 - val_loss: 0.5601 - val_acc: 0.0000e+00\n",
      "Epoch 27/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5490 - acc: 0.0000e+00 - val_loss: 0.5553 - val_acc: 0.0000e+00\n",
      "Epoch 28/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5466 - acc: 0.0000e+00 - val_loss: 0.5709 - val_acc: 0.0000e+00\n",
      "Epoch 29/40\n",
      "2418/2418 [==============================] - 9s - loss: 0.5479 - acc: 0.0000e+00 - val_loss: 0.5530 - val_acc: 0.0000e+00\n",
      "Epoch 30/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5472 - acc: 0.0000e+00 - val_loss: 0.5725 - val_acc: 0.0000e+00\n",
      "Epoch 31/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5395 - acc: 0.0000e+00 - val_loss: 0.5864 - val_acc: 0.0000e+00\n",
      "Epoch 32/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5374 - acc: 0.0000e+00 - val_loss: 0.5737 - val_acc: 0.0000e+00\n",
      "Epoch 33/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5379 - acc: 0.0000e+00 - val_loss: 0.5843 - val_acc: 0.0000e+00\n",
      "Epoch 34/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5351 - acc: 0.0000e+00 - val_loss: 0.5515 - val_acc: 0.0000e+00\n",
      "Epoch 35/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5344 - acc: 0.0000e+00 - val_loss: 0.5574 - val_acc: 0.0000e+00\n",
      "Epoch 36/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5328 - acc: 0.0000e+00 - val_loss: 0.5499 - val_acc: 0.0000e+00\n",
      "Epoch 37/40\n",
      "2418/2418 [==============================] - 9s - loss: 0.5302 - acc: 0.0000e+00 - val_loss: 0.5571 - val_acc: 0.0000e+00\n",
      "Epoch 38/40\n",
      "2418/2418 [==============================] - 9s - loss: 0.5255 - acc: 0.0000e+00 - val_loss: 0.5588 - val_acc: 0.0000e+00\n",
      "Epoch 39/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5272 - acc: 0.0000e+00 - val_loss: 0.5644 - val_acc: 0.0000e+00\n",
      "Epoch 40/40\n",
      "2418/2418 [==============================] - 8s - loss: 0.5259 - acc: 0.0000e+00 - val_loss: 0.5733 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x114d9abd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=100, epochs=40, validation_split=0.05)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outcome = pd.DataFrame()\n",
    "outcome['actual'] = y_test\n",
    "outcome['predicted'] = predicted\n",
    "outcome.to_csv(\"outcome.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
